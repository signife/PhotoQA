{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#CSV combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the CSV file\n",
    "data = pd.read_csv('data/data-1729656846556.csv')\n",
    "data2 = pd.read_csv('data/data-1731975851140.csv')\n",
    "data3 = pd.read_csv('data/data-1732074777669.csv')\n",
    "merged = pd.concat([data, data2, data3], ignore_index=True)\n",
    "duplicate_rows = merged[merged.duplicated()]\n",
    "\n",
    "if len(duplicate_rows) > 0:\n",
    "    print(\"Duplicated rows:\")\n",
    "    print(duplicate_rows)\n",
    "\n",
    "deduplicated = merged.drop_duplicates()\n",
    "\n",
    "deduplicated.to_csv('data/newimage.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#exclude rows with \"pending\" values and only keep rows labeled as \"approved\" or \"declined\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_FILE_PATH = 'data/newimage.csv'\n",
    "df = pd.read_csv(CSV_FILE_PATH)\n",
    "\n",
    "print(len(df))\n",
    "\n",
    "# Filter for rows where image_status is 'Approved' or 'Declined'\n",
    "filtered_df = df[df['image_status'].isin(['Approved', 'Declined'])]\n",
    "\n",
    "print(len(df) - len(filtered_df))\n",
    "# Save the filtered data to a new CSV file\n",
    "output_path = 'data/newimage.csv'  # Replace with your desired save path\n",
    "filtered_df.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#ensure only rows corresponding to existing image files are retained, and rows without associated images are removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "CSV_FILE_PATH = 'data/newimage.csv'\n",
    "IMAGE_DIR = 'data/newimage_cropped'  # 이미지 파일이 저장된 디렉토리 경로\n",
    "\n",
    "df = pd.read_csv(CSV_FILE_PATH)\n",
    "\n",
    "\n",
    "def clean_and_check_image_data(df, image_dir):\n",
    "    # 데이터프레임에 있는 이미지 경로를 기준으로 실제 존재 여부를 확인\n",
    "    valid_data = []\n",
    "    missing_in_metadata = []\n",
    "\n",
    "    # 1. 메타데이터 기준으로 실제 이미지 파일을 체크\n",
    "    for idx, row in df.iterrows():\n",
    "        image_name = row[\"image_name\"]\n",
    "        image_status = row[\"image_status\"]  # approved 또는 declined\n",
    "        status_folder = image_status.lower()  # 폴더 이름 변환 (소문자 처리)\n",
    "        \n",
    "        # 경로 생성\n",
    "        image_path = os.path.join(image_dir, status_folder, image_name)\n",
    "\n",
    "        # 이미지가 존재하는 경우만 valid_data 리스트에 추가\n",
    "        if os.path.exists(image_path):\n",
    "            valid_data.append(row)\n",
    "        else:\n",
    "            print(f\"Image missing: {image_path}\")\n",
    "\n",
    "    # 유효한 데이터를 새로운 DataFrame으로 반환\n",
    "    cleaned_df = pd.DataFrame(valid_data)\n",
    "\n",
    "    return cleaned_df\n",
    "\n",
    "# def clean_and_check_image_data(df, image_dir):\n",
    "#     # 데이터프레임에 있는 이미지 경로를 기준으로 실제 존재 여부를 확인\n",
    "#     valid_data = []\n",
    "#     missing_in_metadata = []\n",
    "\n",
    "#     # 1. 메타데이터 기준으로 실제 이미지 파일을 체크\n",
    "#     for idx, row in df.iterrows():\n",
    "#         job_no = str(row[\"job_no\"])\n",
    "#         image_name = row[\"image_name\"]\n",
    "#         image_path = os.path.join(image_dir, job_no, image_name)\n",
    "\n",
    "#         # 이미지가 존재하는 경우만 valid_data 리스트에 추가\n",
    "#         if os.path.exists(image_path):\n",
    "#             valid_data.append(row)\n",
    "#         else:\n",
    "#             print(f\"Image missing: {image_path}\")\n",
    "\n",
    "#     cleaned_df = pd.DataFrame(valid_data)\n",
    "\n",
    "#     return cleaned_df\n",
    "\n",
    "df2 = clean_and_check_image_data(df, IMAGE_DIR)\n",
    "\n",
    "print(len(df) - len(df2))\n",
    "\n",
    "df2.to_csv('data/newimage.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#manually check 'Images' & 'Expiry Images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "file_path = 'data/cleaned_data.csv'  # Replace with the actual CSV path\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Define the base directory where the images are stored\n",
    "base_directory = 'data/declined+newdeclined/compliances'  # Replace with the actual base directory\n",
    "\n",
    "# Function to display a limited number of images from a given data subset\n",
    "def display_images_from_csv(data_subset, base_dir, limit=10):\n",
    "    count = 0\n",
    "    for _, row in data_subset.iterrows():\n",
    "        if count >= limit:  # Stop after the specified limit\n",
    "            break\n",
    "        job_no = str(row['job_no'])  # Get the job_no to identify the subfolder\n",
    "        image_name = row['image_name']  # Get the image name\n",
    "        \n",
    "        # Construct the full path for the image\n",
    "        image_path = os.path.join(base_dir, job_no, image_name)\n",
    "        try:\n",
    "            # Open and display the image\n",
    "            img = Image.open(image_path)\n",
    "            img.show(title=f\"{row['image_type']} - {image_name}\")\n",
    "            count += 1\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Image not found: {image_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error opening image {image_path}: {e}\")\n",
    "\n",
    "# Filter the CSV data for Images and ExpiryImages\n",
    "images_data = data[data['image_type'] == 'Images']\n",
    "expiry_images_data = data[data['image_type'] == 'ExpiryImages']\n",
    "\n",
    "# Display the first 10 images for each type\n",
    "print(\"Displaying first 10 'Images'...\")\n",
    "display_images_from_csv(images_data, base_directory, limit=10)\n",
    "\n",
    "print(\"Displaying first 10 'ExpiryImages'...\")\n",
    "display_images_from_csv(expiry_images_data, base_directory, limit=10)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Load the original CSV file\n",
    "file_path = 'data/cleaned_data.csv'  # Replace with your CSV file path\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Split the data into two dataframes based on 'image_type'\n",
    "images_data = data[data['image_type'] == 'Images']\n",
    "expiry_images_data = data[data['image_type'] == 'ExpiryImages']\n",
    "\n",
    "# Save the two dataframes to separate CSV files\n",
    "images_csv_path = 'cleaned_data_images.csv'\n",
    "expiry_images_csv_path = 'cleaned_images_expiry.csv'\n",
    "\n",
    "images_data.to_csv(images_csv_path, index=False)\n",
    "expiry_images_data.to_csv(expiry_images_csv_path, index=False)\n",
    "\n",
    "print(f\"Images data saved to {images_csv_path}\")\n",
    "print(f\"Expiry Images data saved to {expiry_images_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "data1 = pd.read_csv('cleaned_data_images.csv')\n",
    "data2 = pd.read_csv('cleaned_images_expiry.csv')\n",
    "\n",
    "\n",
    "def make_reason(data):\n",
    "    # Step 1: Count decline reasons\n",
    "    data_declined = data['decline_reason'].value_counts()\n",
    "    # Step 2: Create a Series for Approved cases\n",
    "    data_approved = pd.Series({'Approved': data[data['image_status'] == 'Approved'].shape[0]})\n",
    "    # Step 3: Combine decline reasons and approved count using pd.concat\n",
    "    data_combined = pd.concat([data_declined, data_approved])\n",
    "\n",
    "    return data_combined\n",
    "\n",
    "\n",
    "def binary_graph(data, title):\n",
    "    count = data['image_status'].value_counts()\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    count.plot(kind='pie', autopct='%1.1f%%', colors=['lightgreen', 'lightcoral'])\n",
    "    plt.title(f'{title}: Distribution')\n",
    "    plt.xlabel('image_status')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(rotation = 0)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def graph(data, title):\n",
    "    # Step 5: Plot a bar chart\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    ax = data.plot(kind='bar', color=['orange', 'blue', 'green', 'red'])  # Customize colors\n",
    "    plt.title(f'{title}:Approved and Declined Reasons Distribution')\n",
    "    plt.xlabel('Category')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(rotation=45)  # Rotate x-axis labels for better readability\n",
    "\n",
    "    for i, value in enumerate(data.values):\n",
    "        ax.text(i, value + 10, str(value), ha='center', va='bottom', fontsize=10)  # Adjust 10 for spacing\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "binary_graph(data1, 'origin image')\n",
    "binary_graph(data2, 'expiry')\n",
    "graph(make_reason(data1), 'origin image')\n",
    "graph(make_reason(data2), 'expiry')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('cleaned_images_expiry.csv')\n",
    "# Filter the dataset for declined images with the reason \"No reference point\"\n",
    "filtered_data = data[(data['image_status'] == 'Declined') & (data['decline_reason'] == 'No reference point')]\n",
    "\n",
    "# Define the directory where images are stored\n",
    "image_base_path = 'data/declined+newdeclined/compliances'  # Replace with your actual image folder path\n",
    "\n",
    "# Display filtered images\n",
    "for index, row in filtered_data.iterrows():\n",
    "    # Construct the image path using job_no and image_name\n",
    "    job_no = str(row['job_no'])  # Convert job_no to string\n",
    "    image_name = row['image_name']  # Get the image name\n",
    "    image_path = os.path.join(image_base_path, job_no, image_name)  # Include job_no as a subdirectory\n",
    "    \n",
    "    try:\n",
    "        # Open and display the image\n",
    "        img = Image.open(image_path)\n",
    "        img.show(title=image_name)  # Display the image with its name as the title\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Image not found: {image_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error opening image {image_path}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#change directory structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import os\n",
    "# 디렉터리 설정\n",
    "cleaned_data = pd.read_csv(\"data/cleaned_data.csv\")\n",
    "\n",
    "\n",
    "source_root = \"data/declined+newdeclined/compliances\"  # 원본 데이터 디렉터리\n",
    "destination_root = \"data/newimage\"  # 새 데이터 디렉터리\n",
    "\n",
    "# Approved 및 Declined 폴더 생성\n",
    "approved_dir = os.path.join(destination_root, \"approved\")\n",
    "declined_dir = os.path.join(destination_root, \"declined\")\n",
    "os.makedirs(approved_dir, exist_ok=True)\n",
    "os.makedirs(declined_dir, exist_ok=True)\n",
    "\n",
    "# 이미지 이동 작업\n",
    "for index, row in cleaned_data.iterrows():\n",
    "    job_no = str(row[\"job_no\"])  # 작업 번호\n",
    "    image_name = row[\"image_name\"]  # 이미지 이름\n",
    "    image_status = row[\"image_status\"]  # Approved 또는 Declined\n",
    "\n",
    "    # 원본 이미지 경로\n",
    "    source_path = os.path.join(source_root, job_no, image_name)\n",
    "\n",
    "    # 대상 경로 설정\n",
    "    if image_status == \"Approved\":\n",
    "        dest_path = os.path.join(approved_dir, image_name)\n",
    "    elif image_status == \"Declined\":\n",
    "        dest_path = os.path.join(declined_dir, image_name)\n",
    "    else:\n",
    "        continue  # Approved 또는 Declined가 아니면 스킵\n",
    "\n",
    "    # 이미지 복사\n",
    "    if os.path.exists(source_path):\n",
    "        shutil.copy2(source_path, dest_path)\n",
    "    else:\n",
    "        print(f\"파일 없음: {source_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/newimage.csv')\n",
    "\n",
    "print(data['image_status'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'image_status'가 'expiryimage'인 경우만 필터링\n",
    "expiryimage_counts = data[data['image_type'] == 'ExpiryImages']['image_status'].value_counts()\n",
    "\n",
    "print(expiryimage_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = 'data/newimage.csv'  # 로컬 파일 경로로 변경\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Group by 'image_type' and calculate the distribution of 'image_status'\n",
    "image_type_distributions = data.groupby('image_type')['image_status'].value_counts(normalize=True).unstack()\n",
    "\n",
    "# Display the distribution as a table\n",
    "print(\"Image Type Distributions:\")\n",
    "print(image_type_distributions)\n",
    "\n",
    "# Visualize the distribution with a bar plot\n",
    "image_type_distributions.plot(kind='bar', stacked=True, figsize=(10, 6))\n",
    "plt.title(\"Image Status Distribution by Image Type\")\n",
    "plt.ylabel(\"Proportion\")\n",
    "plt.xlabel(\"Image Type\")\n",
    "plt.legend(title=\"Image Status\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def stratified_undersample(data, image_type_col, status_col, random_state=42):\n",
    "    \"\"\"\n",
    "    Performs stratified undersampling for Approved data based on Declined ratio per image_type.\n",
    "\n",
    "    Parameters:\n",
    "        data (pd.DataFrame): The input dataset.\n",
    "        image_type_col (str): The column name for image type (e.g., 'image_type').\n",
    "        status_col (str): The column name for status (e.g., 'image_status').\n",
    "        random_state (int): Random state for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Stratified undersampled dataset.\n",
    "    \"\"\"\n",
    "    balanced_data = []\n",
    "    \n",
    "    for image_type, group in data.groupby(image_type_col):\n",
    "        approved = group[group[status_col] == 'Approved']\n",
    "        declined = group[group[status_col] == 'Declined']\n",
    "        \n",
    "        # Calculate target size for Approved based on Declined size and existing ratio\n",
    "        declined_count = len(declined)\n",
    "        target_approved_count = int(declined_count / (1 - declined_count / len(group)))\n",
    "\n",
    "        # Undersample Approved if necessary\n",
    "        if len(approved) > target_approved_count:\n",
    "            undersampled_approved = approved.sample(n=target_approved_count, random_state=random_state)\n",
    "        else:\n",
    "            undersampled_approved = approved\n",
    "        \n",
    "        # Combine undersampled Approved and Declined\n",
    "        balanced_group = pd.concat([undersampled_approved, declined])\n",
    "        balanced_data.append(balanced_group)\n",
    "    \n",
    "    return pd.concat(balanced_data)\n",
    "\n",
    "# Perform stratified undersampling\n",
    "balanced_data = stratified_undersample(data, 'image_type', 'image_status')\n",
    "\n",
    "# Check the new distribution\n",
    "balanced_distributions = balanced_data.groupby('image_type')['image_status'].value_counts(normalize=True).unstack()\n",
    "\n",
    "# Save the balanced data and display the new distribution\n",
    "balanced_data.to_csv('data/newimage_undersampled.csv', index=False)\n",
    "\n",
    "# Display the distribution in the terminal\n",
    "print(\"Balanced Image Type Distributions:\")\n",
    "print(balanced_distributions)\n",
    "\n",
    "# Optional: Visualize the distribution with a bar plot\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Plot bar chart for the distributions\n",
    "balanced_distributions.plot(kind='bar', stacked=True, figsize=(10, 6))\n",
    "\n",
    "# Add title and labels\n",
    "plt.title(\"Balanced Image Type Distributions\")\n",
    "plt.ylabel(\"Proportion\")\n",
    "plt.xlabel(\"Image Type\")\n",
    "plt.legend(title=\"Image Status\")\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "print(balanced_data['image_status'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
