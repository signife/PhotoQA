{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#CSV combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the CSV file\n",
    "data = pd.read_csv('data/data-1729656846556.csv')\n",
    "data2 = pd.read_csv('data/data-1731975851140.csv')\n",
    "data3 = pd.read_csv('data/data-1732074777669.csv')\n",
    "merged = pd.concat([data, data2, data3], ignore_index=True)\n",
    "duplicate_rows = merged[merged.duplicated()]\n",
    "\n",
    "if len(duplicate_rows) > 0:\n",
    "    print(\"Duplicated rows:\")\n",
    "    print(duplicate_rows)\n",
    "\n",
    "deduplicated = merged.drop_duplicates()\n",
    "\n",
    "deduplicated.to_csv('data/newimage.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#exclude rows with \"pending\" values and only keep rows labeled as \"approved\" or \"declined\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_FILE_PATH = 'data/newimage.csv'\n",
    "df = pd.read_csv(CSV_FILE_PATH)\n",
    "\n",
    "print(len(df))\n",
    "\n",
    "# Filter for rows where image_status is 'Approved' or 'Declined'\n",
    "filtered_df = df[df['image_status'].isin(['Approved', 'Declined'])]\n",
    "\n",
    "print(len(df) - len(filtered_df))\n",
    "# Save the filtered data to a new CSV file\n",
    "output_path = 'data/newimage.csv'  # Replace with your desired save path\n",
    "filtered_df.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#ensure only rows corresponding to existing image files are retained, and rows without associated images are removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "CSV_FILE_PATH = 'data/newimage.csv'\n",
    "IMAGE_DIR = 'data/newimage_cropped'  # Directory path where image files are stored\n",
    "\n",
    "df = pd.read_csv(CSV_FILE_PATH)\n",
    "\n",
    "\n",
    "def clean_and_check_image_data(df, image_dir):\n",
    "    # Verify the existence of images based on paths listed in the DataFrame\n",
    "    valid_data = []\n",
    "    missing_in_metadata = []\n",
    "\n",
    "    # 1. Check image files based on metadata\n",
    "    for idx, row in df.iterrows():\n",
    "        image_name = row[\"image_name\"]\n",
    "        image_status = row[\"image_status\"]  # Either \"approved\" or \"declined\"\n",
    "        status_folder = image_status.lower()  # Convert folder name to lowercase\n",
    "        \n",
    "        # Construct the image path\n",
    "        image_path = os.path.join(image_dir, status_folder, image_name)\n",
    "\n",
    "        # Add to valid_data list only if the image exists\n",
    "        if os.path.exists(image_path):\n",
    "            valid_data.append(row)\n",
    "        else:\n",
    "            print(f\"Image missing: {image_path}\")\n",
    "\n",
    "    # Return a new DataFrame containing only valid data\n",
    "    cleaned_df = pd.DataFrame(valid_data)\n",
    "\n",
    "    return cleaned_df\n",
    "\n",
    "\n",
    "df2 = clean_and_check_image_data(df, IMAGE_DIR)\n",
    "\n",
    "print(len(df) - len(df2))  # Print the number of missing images\n",
    "\n",
    "df2.to_csv('data/newimage.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#manually check 'Images' & 'Expiry Images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "file_path = ''  # Replace with the actual CSV path\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Define the base directory where the images are stored\n",
    "base_directory = ''  # Replace with the actual base directory\n",
    "\n",
    "# Function to display a limited number of images from a given data subset\n",
    "def display_images_from_csv(data_subset, base_dir, limit=10):\n",
    "    count = 0\n",
    "    for _, row in data_subset.iterrows():\n",
    "        if count >= limit:  # Stop after the specified limit\n",
    "            break\n",
    "        job_no = str(row['job_no'])  # Get the job_no to identify the subfolder\n",
    "        image_name = row['image_name']  # Get the image name\n",
    "        \n",
    "        # Construct the full path for the image\n",
    "        image_path = os.path.join(base_dir, job_no, image_name)\n",
    "        try:\n",
    "            # Open and display the image\n",
    "            img = Image.open(image_path)\n",
    "            img.show(title=f\"{row['image_type']} - {image_name}\")\n",
    "            count += 1\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Image not found: {image_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error opening image {image_path}: {e}\")\n",
    "\n",
    "# Filter the CSV data for Images and ExpiryImages\n",
    "images_data = data[data['image_type'] == 'Images']\n",
    "expiry_images_data = data[data['image_type'] == 'ExpiryImages']\n",
    "\n",
    "# Display the first 10 images for each type\n",
    "print(\"Displaying first 10 'Images'...\")\n",
    "display_images_from_csv(images_data, base_directory, limit=10)\n",
    "\n",
    "print(\"Displaying first 10 'ExpiryImages'...\")\n",
    "display_images_from_csv(expiry_images_data, base_directory, limit=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#The task is to split the CSV file into two separate files: Images and ExpiryImages. The '11th_train_practice' combined both for training purposes, so it doesn't need to be used here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Load the original CSV file\n",
    "file_path = ''  # Replace with your CSV file path\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Split the data into two dataframes based on 'image_type'\n",
    "images_data = data[data['image_type'] == 'Images']\n",
    "expiry_images_data = data[data['image_type'] == 'ExpiryImages']\n",
    "\n",
    "# Save the two dataframes to separate CSV files\n",
    "images_csv_path = 'cleaned_data_images.csv'\n",
    "expiry_images_csv_path = 'cleaned_images_expiry.csv'\n",
    "\n",
    "images_data.to_csv(images_csv_path, index=False)\n",
    "expiry_images_data.to_csv(expiry_images_csv_path, index=False)\n",
    "\n",
    "print(f\"Images data saved to {images_csv_path}\")\n",
    "print(f\"Expiry Images data saved to {expiry_images_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To Check the distribution of image_status\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "data1 = pd.read_csv('cleaned_data_images.csv')\n",
    "data2 = pd.read_csv('cleaned_images_expiry.csv')\n",
    "\n",
    "\n",
    "def make_reason(data):\n",
    "    # Step 1: Count decline reasons\n",
    "    data_declined = data['decline_reason'].value_counts()\n",
    "    # Step 2: Create a Series for Approved cases\n",
    "    data_approved = pd.Series({'Approved': data[data['image_status'] == 'Approved'].shape[0]})\n",
    "    # Step 3: Combine decline reasons and approved count using pd.concat\n",
    "    data_combined = pd.concat([data_declined, data_approved])\n",
    "\n",
    "    return data_combined\n",
    "\n",
    "\n",
    "def binary_graph(data, title):\n",
    "    count = data['image_status'].value_counts()\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    count.plot(kind='pie', autopct='%1.1f%%', colors=['lightgreen', 'lightcoral'])\n",
    "    plt.title(f'{title}: Distribution')\n",
    "    plt.xlabel('image_status')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(rotation = 0)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def graph(data, title):\n",
    "    # Step 5: Plot a bar chart\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    ax = data.plot(kind='bar', color=['orange', 'blue', 'green', 'red'])  # Customize colors\n",
    "    plt.title(f'{title}:Approved and Declined Reasons Distribution')\n",
    "    plt.xlabel('Category')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(rotation=45)  # Rotate x-axis labels for better readability\n",
    "\n",
    "    for i, value in enumerate(data.values):\n",
    "        ax.text(i, value + 10, str(value), ha='center', va='bottom', fontsize=10)  # Adjust 10 for spacing\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "binary_graph(data1, 'origin image')\n",
    "binary_graph(data2, 'expiry')\n",
    "graph(make_reason(data1), 'origin image')\n",
    "graph(make_reason(data2), 'expiry')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To display the images with the decline reason\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('cleaned_images_expiry.csv')\n",
    "# Filter the dataset for declined images with the reason \"No reference point\"\n",
    "filtered_data = data[(data['image_status'] == 'Declined') & (data['decline_reason'] == 'No reference point')]\n",
    "\n",
    "# Define the directory where images are stored\n",
    "image_base_path = 'data/declined+newdeclined/compliances'  # Replace with your actual image folder path\n",
    "\n",
    "# Display filtered images\n",
    "for index, row in filtered_data.iterrows():\n",
    "    # Construct the image path using job_no and image_name\n",
    "    job_no = str(row['job_no'])  # Convert job_no to string\n",
    "    image_name = row['image_name']  # Get the image name\n",
    "    image_path = os.path.join(image_base_path, job_no, image_name)  # Include job_no as a subdirectory\n",
    "    \n",
    "    try:\n",
    "        # Open and display the image\n",
    "        img = Image.open(image_path)\n",
    "        img.show(title=image_name)  # Display the image with its name as the title\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Image not found: {image_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error opening image {image_path}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('data/newimage.csv')\n",
    "\n",
    "print(data['image_status'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_counts = data[data['image_type'] == 'Images']['image_status'].value_counts()\n",
    "expiryimage_counts = data[data['image_type'] == 'ExpiryImages']['image_status'].value_counts()\n",
    "\n",
    "\n",
    "print(image_counts)\n",
    "print(expiryimage_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = 'data/newimage.csv'  #Replace with the actual path\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Group by 'image_type' and calculate the distribution of 'image_status'\n",
    "image_type_distributions = data.groupby('image_type')['image_status'].value_counts(normalize=True).unstack()\n",
    "image_type_counts = data.groupby('image_type')['image_status'].value_counts().unstack()\n",
    "\n",
    "# Display the distribution as a table\n",
    "print(\"Image Type Distributions:\")\n",
    "print(image_type_distributions)\n",
    "\n",
    "# Prepare bar chart\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "image_type_counts.plot(kind='bar', stacked=True, ax=ax)\n",
    "\n",
    "# Add title and labels\n",
    "plt.title(\"Image Status Distribution by Image Type\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xlabel(\"Image Type\")\n",
    "plt.legend(title=\"Image Status\")\n",
    "plt.tight_layout()\n",
    "\n",
    "# Add text labels on bars\n",
    "for container in ax.containers:\n",
    "    for bar in container:\n",
    "        height = bar.get_height()\n",
    "        if height > 0:\n",
    "            ax.text(\n",
    "                bar.get_x() + bar.get_width() / 2,\n",
    "                bar.get_y() + height / 2,\n",
    "                f'{int(height)}',  # Convert height to integer\n",
    "                ha='center',\n",
    "                va='center',\n",
    "                fontsize=10,\n",
    "                color='white'  # Ensure text is visible on the bar\n",
    "            )\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def stratified_undersample(data, image_type_col, status_col, random_state=42):\n",
    "    \"\"\"\n",
    "    Performs stratified undersampling for Approved data based on Declined ratio per image_type.\n",
    "\n",
    "    Parameters:\n",
    "        data (pd.DataFrame): The input dataset.\n",
    "        image_type_col (str): The column name for image type (e.g., 'image_type').\n",
    "        status_col (str): The column name for status (e.g., 'image_status').\n",
    "        random_state (int): Random state for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Stratified undersampled dataset.\n",
    "    \"\"\"\n",
    "    balanced_data = []\n",
    "    \n",
    "    for image_type, group in data.groupby(image_type_col):\n",
    "        approved = group[group[status_col] == 'Approved']\n",
    "        declined = group[group[status_col] == 'Declined']\n",
    "        \n",
    "        # Calculate target size for Approved based on Declined size and existing ratio\n",
    "        declined_count = len(declined)\n",
    "        target_approved_count = int(declined_count / (1 - declined_count / len(group)))\n",
    "\n",
    "        # Undersample Approved if necessary\n",
    "        if len(approved) > target_approved_count:\n",
    "            undersampled_approved = approved.sample(n=target_approved_count, random_state=random_state)\n",
    "        else:\n",
    "            undersampled_approved = approved\n",
    "        \n",
    "        # Combine undersampled Approved and Declined\n",
    "        balanced_group = pd.concat([undersampled_approved, declined])\n",
    "        balanced_data.append(balanced_group)\n",
    "    \n",
    "    return pd.concat(balanced_data)\n",
    "\n",
    "# Perform stratified undersampling\n",
    "balanced_data = stratified_undersample(data, 'image_type', 'image_status')\n",
    "\n",
    "# Check the new distribution\n",
    "balanced_distributions = balanced_data.groupby('image_type')['image_status'].value_counts(normalize=True).unstack()\n",
    "\n",
    "# Save the balanced data and display the new distribution\n",
    "balanced_data.to_csv('data/newimage_undersampled.csv', index=False)\n",
    "\n",
    "# Display the distribution in the terminal\n",
    "print(\"Balanced Image Type Distributions:\")\n",
    "print(balanced_distributions)\n",
    "\n",
    "# Optional: Visualize the distribution with a bar plot\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "data = balanced_data\n",
    "\n",
    "image_type_distributions = data.groupby('image_type')['image_status'].value_counts(normalize=True).unstack()\n",
    "image_type_counts = data.groupby('image_type')['image_status'].value_counts().unstack()\n",
    "\n",
    "# Display the distribution as a table\n",
    "print(\"Image Type Distributions:\")\n",
    "print(image_type_distributions)\n",
    "\n",
    "# Prepare bar chart\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "image_type_counts.plot(kind='bar', stacked=True, ax=ax)\n",
    "\n",
    "# Add title and labels\n",
    "plt.title(\"Image Status Distribution by Image Type\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xlabel(\"Image Type\")\n",
    "plt.legend(title=\"Image Status\")\n",
    "plt.tight_layout()\n",
    "\n",
    "# Add text labels on bars\n",
    "for container in ax.containers:\n",
    "    for bar in container:\n",
    "        height = bar.get_height()\n",
    "        if height > 0:\n",
    "            ax.text(\n",
    "                bar.get_x() + bar.get_width() / 2,\n",
    "                bar.get_y() + height / 2,\n",
    "                f'{int(height)}',  # Convert height to integer\n",
    "                ha='center',\n",
    "                va='center',\n",
    "                fontsize=10,\n",
    "                color='white'  # Ensure text is visible on the bar\n",
    "            )\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
