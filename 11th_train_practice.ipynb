{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XQANwuN06gPe",
    "outputId": "5b019ee4-1981-49f4-f8d6-697a087b10ba"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ehZaPIKNjNpz"
   },
   "source": [
    "#make meta data, remove null label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yTq4ciqEjNS_"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "CSV_FILE_PATH = ''\n",
    "IMAGE_DIR = ''\n",
    "\n",
    "df = pd.read_csv(CSV_FILE_PATH)\n",
    "\n",
    "def clean_and_check_image_data(df, image_dir):\n",
    "    valid_data = []\n",
    "    missing_in_metadata = []\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        job_no = str(row[\"job_no\"])\n",
    "        image_name = row[\"image_name\"]\n",
    "        image_path = os.path.join(image_dir, job_no, image_name)\n",
    "\n",
    "        if os.path.exists(image_path):\n",
    "            valid_data.append(row)\n",
    "        else:\n",
    "            print(f\"Image missing: {image_path}\")\n",
    "\n",
    "    cleaned_df = pd.DataFrame(valid_data)\n",
    "\n",
    "    return cleaned_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QQCpXvKWkqYp",
    "outputId": "99904717-54e9-4f16-d92f-a64d3f0340cd"
   },
   "outputs": [],
   "source": [
    "\n",
    "df2 = clean_and_check_image_data(df, IMAGE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kGmvXSaIlnlk",
    "outputId": "4d647bf2-61bb-4f1d-f0c0-38a34a1e35df"
   },
   "outputs": [],
   "source": [
    "print(len(df),len(df2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OKTGaaLDrs15"
   },
   "outputs": [],
   "source": [
    "df = df2\n",
    "df.to_csv('', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8XLx1_L0MDc9"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SPEmFGsrL7_7"
   },
   "source": [
    "#import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PICE6uA27WWY"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "from tqdm import tqdm  # Import tqdm for the progress bar\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from tqdm import tqdm\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, balanced_accuracy_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "\n",
    "\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "torch.cuda.empty_cache()\n",
    "from torch.utils.data import WeightedRandomSampler # for data augmentation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6JbGHV65gcQr"
   },
   "source": [
    "#Common.py: including configuration, seed_everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wAa-c13A9IlO"
   },
   "outputs": [],
   "source": [
    "# Paths\n",
    "CSV_FILE_PATH = ''\n",
    "IMAGE_DIR = ''\n",
    "\n",
    "#Image resolution\n",
    "IMG_SIZE = 456\n",
    "\n",
    "# DataLoader settings\n",
    "BATCH_SIZE = 16\n",
    "# Training settings\n",
    "NUM_EPOCHS = 10\n",
    "LEARNING_RATE = 1e-3 #3e-4 #0.001 -> 0.0003\n",
    "\n",
    "# Normalization parameters for pretrained models\n",
    "NORMALIZE_MEAN = [0.485, 0.456, 0.406]\n",
    "NORMALIZE_STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "SEED = 42\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F_iRzq2bhWOP"
   },
   "source": [
    "#data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h0e18PJ0tWWj"
   },
   "outputs": [],
   "source": [
    "# Define a PyTorch Dataset\n",
    "class SmokeAlarmDataset(Dataset):\n",
    "    def __init__(self, df, image_dir, transform=None):\n",
    "        self.df = df\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "        self.label_map = {\"Approved\": 1, \"Declined\": 0}\n",
    "        self.type_map = {\"ExpiryImages\": 1, \"Images\": 0}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get job number and image name\n",
    "        image_name = self.df.iloc[idx][\"image_name\"]\n",
    "\n",
    "        # Map the label\n",
    "        label = self.df.iloc[idx][\"image_status\"]\n",
    "        label = self.label_map.get(label, 0)\n",
    "\n",
    "        # Map the image_status\n",
    "        image_status = self.df.iloc[idx][\"image_status\"]\n",
    "        type_channel_value = self.type_map.get(image_status, 0)\n",
    "\n",
    "        if image_status == \"Approved\":\n",
    "            folder = \"approved\"\n",
    "        elif image_status == \"Declined\":\n",
    "            folder = \"declined\"\n",
    "        else:\n",
    "            raise ValueError(f\"Unexpected image_status: {image_status}\")\n",
    "\n",
    "        # Construct image path and load the image\n",
    "        image_path = os.path.join(self.image_dir, folder, image_name)\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert to RGB\n",
    "\n",
    "        # Create image type channel\n",
    "        type_channel = np.full((image.shape[0], image.shape[1], 1), type_channel_value, dtype=np.uint8)\n",
    "\n",
    "        # combine image & image_status\n",
    "        combined_image = np.concatenate((image, type_channel), axis=-1)  # (H, W, 4)\n",
    "\n",
    "        # Apply transform if available\n",
    "        if self.transform:\n",
    "            combined_image = self.transform(image=combined_image)[\"image\"]\n",
    "\n",
    "        # Return image and label\n",
    "        return combined_image, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GN7DHwVuui0B"
   },
   "source": [
    "#model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iqkYCrFwtW2T"
   },
   "outputs": [],
   "source": [
    "class BaseModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BaseModel, self).__init__()\n",
    "        self.backbone = models.efficientnet_b5(pretrained=True)  # pretrained 대신 weights 사용\n",
    "\n",
    "        self.backbone.features[0][0] = nn.Conv2d(\n",
    "            in_channels = 4,\n",
    "            out_channels = 48,\n",
    "            kernel_size = (3,3),\n",
    "            stride = (2,2),\n",
    "            padding = (1,1),\n",
    "            bias = False\n",
    "        )\n",
    "\n",
    "        # modify the output layer of EfficientNet to match the number of classes\n",
    "        self.backbone.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.3, inplace=True),\n",
    "            nn.Linear(self.backbone.classifier[1].in_features, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "75LsLpk4ukVu"
   },
   "source": [
    "#train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uJLzr5KsumPJ"
   },
   "outputs": [],
   "source": [
    "from albumentations.core.transforms_interface import ImageOnlyTransform\n",
    "\n",
    "class ToTensorV2Custom(ImageOnlyTransform):\n",
    "    def __init__(self, always_apply=False, p=1.0):\n",
    "        super(ToTensorV2Custom, self).__init__(always_apply, p)\n",
    "\n",
    "    def apply(self, img, **params):\n",
    "        # Albumentations expects images in HWC format (Height, Width, Channels)\n",
    "        return torch.from_numpy(img.transpose(2, 0, 1))  # Convert to CHW format\n",
    "\n",
    "    def get_transform_init_args_names(self):\n",
    "        return ()\n",
    "\n",
    "\n",
    "train_transform = A.Compose([\n",
    "\n",
    "        A.Resize(IMG_SIZE, IMG_SIZE),\n",
    "        A.Normalize(mean = NORMALIZE_MEAN, std = NORMALIZE_STD,\n",
    "                    max_pixel_value= 255.0, always_apply=False, p = 1.0), #normalization\n",
    "        ToTensorV2Custom()\n",
    "\n",
    "])\n",
    "\n",
    "test_transform = A.Compose([\n",
    "\n",
    "        A.Resize(IMG_SIZE, IMG_SIZE),\n",
    "        A.Normalize(mean = NORMALIZE_MEAN, std = NORMALIZE_STD,\n",
    "                    max_pixel_value= 255.0, always_apply=False, p = 1.0), #normalization\n",
    "        ToTensorV2Custom()\n",
    "\n",
    "])\n",
    "\n",
    "df = pd.read_csv(CSV_FILE_PATH)\n",
    "#adding weight\n",
    "num_declined = (df['image_status'] == 'Declined').sum()  # Declined 클래스 수\n",
    "num_approved = (df['image_status'] == 'Approved').sum()  # Approved 클래스 수\n",
    "pos_weight = torch.tensor([num_approved / num_declined], dtype=torch.float).to(DEVICE)\n",
    "\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "\n",
    "#get rid of sampler(adding weight to prevent overfitting)\n",
    "def load_data(df, image_dir, train_transform, test_transform, batch_size):\n",
    "\n",
    "    # Split data into train, validation, and test sets\n",
    "    train_df, temp_df = train_test_split(df, test_size=0.3, random_state=42, stratify=df['image_status'])\n",
    "    val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42, stratify=temp_df['image_status'])\n",
    "\n",
    "    # Initialize datasets\n",
    "    train_dataset = SmokeAlarmDataset(train_df, image_dir, transform=train_transform)\n",
    "    val_dataset = SmokeAlarmDataset(val_df, image_dir, transform=test_transform)\n",
    "    test_dataset = SmokeAlarmDataset(test_df, image_dir, transform=test_transform)\n",
    "\n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # return train_loader, val_loader, test_loader, le\n",
    "    return train_loader, val_loader, test_loader, train_df, val_df, test_df\n",
    "\n",
    "\n",
    "def train(model, train_loader, val_loader, criterion, optimizer, scheduler, DEVICE):\n",
    "    model.to(DEVICE)\n",
    "    best_score = 0\n",
    "    best_model = None\n",
    "    train_losses = []\n",
    "    train_mAPs = []\n",
    "    val_losses = []\n",
    "    val_mAPs = []\n",
    "    all_train_labels = []  # save train true_labels for all epochs\n",
    "    all_train_probs = []   # save train predictions_prob for all epochs\n",
    "    all_val_labels = []    # save val true_labels for all epochs\n",
    "    all_val_probs = []     # save val predictions_prob for all epochs\n",
    "\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        model.train()\n",
    "        batch_losses = []\n",
    "        true_labels = []\n",
    "        predictions_prob = []\n",
    "\n",
    "        # Training Loop\n",
    "        for img, label in tqdm(iter(train_loader), desc=f\"Training Epoch {epoch + 1}/{NUM_EPOCHS}\"):\n",
    "            label = label = label.float()\n",
    "            img, label = img.float().to(DEVICE), label.to(DEVICE)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(img)\n",
    "            loss = criterion(pred, label.unsqueeze(1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            batch_losses.append(loss.item())\n",
    "\n",
    "            # Save predicted and true labels\n",
    "            true_labels += label.int().cpu().numpy().flatten().tolist()\n",
    "            predictions_prob += pred.sigmoid().detach().cpu().numpy().flatten().tolist()\n",
    "\n",
    "        # Calculate the average training loss for this epoch\n",
    "        avg_train_loss = np.mean(batch_losses)\n",
    "        train_losses.append(avg_train_loss)\n",
    "\n",
    "        # Calculate mAP\n",
    "        train_mAP = average_precision_score(true_labels, predictions_prob)\n",
    "        train_mAPs.append(train_mAP)\n",
    "\n",
    "        # Save true_labels and predictions_prob for the current epoch of training\n",
    "        all_train_labels.append(true_labels)\n",
    "        all_train_probs.append(predictions_prob)\n",
    "\n",
    "        # Validation step\n",
    "        val_results = validation(model, criterion, val_loader, DEVICE)\n",
    "        val_losses.append(val_results[\"val_loss\"])\n",
    "        val_mAPs.append(val_results[\"val_mAP\"])\n",
    "\n",
    "        # Save true_labels and predictions_prob for the validation data\n",
    "        all_val_labels.append(val_results[\"true_labels\"])\n",
    "        all_val_probs.append(val_results[\"predictions_prob\"])\n",
    "\n",
    "        # Print results for the current epoch\n",
    "        print(f\"Epoch [{epoch + 1}/{NUM_EPOCHS}], Train Loss: {avg_train_loss:.5f}, Train mAP: {train_mAP:.5f}, \"\n",
    "              f\"Val Loss: {val_results['val_loss']:.5f}, Val mAP: {val_results['val_mAP']:.5f}\")\n",
    "\n",
    "        # Save the best performing model\n",
    "        if val_results[\"val_mAP\"] > best_score:\n",
    "            best_score = val_results[\"val_mAP\"]\n",
    "            best_model = model.state_dict()  # Save model weights\n",
    "\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "\n",
    "    return train_losses, train_mAPs, val_losses, val_mAPs, all_train_labels, all_train_probs, all_val_labels, all_val_probs, best_model\n",
    "\n",
    "# Updated validation function with DEVICE applied\n",
    "def validation(model, criterion, val_loader, DEVICE):\n",
    "    model.eval()\n",
    "    model_pred = []\n",
    "    true_labels = []\n",
    "    val_loss = []\n",
    "    predictions_prob = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for img, label in tqdm(iter(val_loader)):\n",
    "            label = label.type(torch.FloatTensor)\n",
    "            img, label = img.float().to(DEVICE), label.to(DEVICE)\n",
    "\n",
    "            pred = model(img)\n",
    "            loss = criterion(pred, label.unsqueeze(1))\n",
    "\n",
    "            val_loss.append(loss.item())\n",
    "\n",
    "            predictions_prob += pred.sigmoid().detach().cpu().numpy().flatten().tolist()\n",
    "            model_pred += (pred.sigmoid() > 0.5).int().cpu().numpy().flatten().tolist() # Save binary predictions\n",
    "            true_labels += label.detach().cpu().numpy().tolist()\n",
    "\n",
    "    avg_val_loss = np.mean(val_loss)\n",
    "    val_mAP = average_precision_score(true_labels, predictions_prob)\n",
    "\n",
    "    return {\n",
    "        \"val_loss\": avg_val_loss,\n",
    "        \"val_mAP\": val_mAP,\n",
    "        \"true_labels\": true_labels,          # Return true_labels for PR Curve\n",
    "        \"predictions_prob\": predictions_prob  # Return predictions_prob for PR Curve\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VNNabydZQXr0"
   },
   "source": [
    "#train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "99C3LYnoB4go",
    "outputId": "1d0afebd-5ed6-47c3-a87d-759e9345ba8d"
   },
   "outputs": [],
   "source": [
    "\n",
    "train_loader, val_loader, test_loader, train_df, val_df, test_df = load_data(df,IMAGE_DIR,train_transform,test_transform,BATCH_SIZE)\n",
    "\n",
    "seed_everything(seed= 42)\n",
    "\n",
    "model = BaseModel()\n",
    "\n",
    "optimizer = torch.optim.Adam(params = model.parameters(), lr=LEARNING_RATE)#lr=1e-3\n",
    "\n",
    "scheduler = None # i also remove it\n",
    "\n",
    "# Train the model with the correct argument order\n",
    "train_losses, train_mAPs, val_losses, val_mAPs, all_train_labels, all_train_probs, all_val_labels, all_val_probs, best_model_weights = train(\n",
    "    model, train_loader, val_loader, criterion, optimizer, scheduler, DEVICE\n",
    ")\n",
    "\n",
    "torch.save(best_model_weights, 'model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "THpmAnSBG6JG"
   },
   "source": [
    "#train/validation curve, loss, mAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 957
    },
    "id": "INiwzxu7vPSg",
    "outputId": "04dc50bc-c7d7-4a7a-ae9a-2ab34ed69fd9"
   },
   "outputs": [],
   "source": [
    "# torch.save(best_model_weights,'/content/drive/MyDrive/PhotoQA/model.pt')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, precision_recall_curve\n",
    "\n",
    "# 1. Train/Validation Loss Curve\n",
    "def plot_loss_curve(train_losses, val_losses):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(train_losses, label='Train Loss')\n",
    "    plt.plot(val_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Train and Validation Loss Curve')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# 2. Train/Validation mAP Curve\n",
    "def plot_map_curve(train_mAPs, val_mAPs):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(train_mAPs, label='Train mAP')\n",
    "    plt.plot(val_mAPs, label='Validation mAP')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('mAP')\n",
    "    plt.title('Train and Validation mAP Curve')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# 3. Confusion Matrix\n",
    "def plot_confusion_matrix(true_labels, predictions, class_names):\n",
    "    cm = confusion_matrix(true_labels, predictions)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "    disp.plot(cmap='Blues')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "# 4. PR Curve\n",
    "def plot_pr_curve(true_labels, predictions_prob):\n",
    "    precision, recall, _ = precision_recall_curve(true_labels, predictions_prob)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(recall, precision, marker='.')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall Curve')\n",
    "    plt.show()\n",
    "\n",
    "#train_losses, train_mAPs, val_losses, val_mAPs\n",
    "#all_train_labels, all_train_probs, all_val_labels, all_val_probs, best_model_weights\n",
    "plot_loss_curve(train_losses, val_losses)\n",
    "plot_map_curve(train_mAPs, val_mAPs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5li2cnM-FW9G"
   },
   "source": [
    "#test.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6dL-fGp7CDus"
   },
   "outputs": [],
   "source": [
    "def inference(model, test_loader, device):\n",
    "    model.eval()\n",
    "    model_pred = []          # Store binary predictions\n",
    "    predictions_prob = []    # Store prediction probabilities\n",
    "    true_labels = []         # Store true labels (if labels are available in the test dataset)\n",
    "    samples = []             # Store tuples of (image, predicted class, prediction probability)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(iter(test_loader)):\n",
    "            # If data is in the form of (images, labels) or (images,), consider the first element as images\n",
    "            if isinstance(data, (list, tuple)):\n",
    "                img = data[0]  # Use the first element as the image tensor\n",
    "                if len(data) > 1:\n",
    "                    true_labels += data[1].cpu().numpy().tolist()  # Store true labels\n",
    "            else:\n",
    "                img = data\n",
    "\n",
    "            img = img.float().to(device)\n",
    "            pred = model(img)\n",
    "\n",
    "            # Convert logits to probabilities using Sigmoid and classify based on a threshold of 0.5\n",
    "            prob = pred.sigmoid().detach().cpu().numpy().flatten()  # Store prediction probabilities\n",
    "            predictions_prob.extend(prob)\n",
    "            class_pred = (prob > 0.5).astype(int).tolist()          # Convert to predicted classes\n",
    "            model_pred.extend(class_pred)\n",
    "\n",
    "            # Store samples with image and prediction information (for test visualization)\n",
    "            for image, prediction, probability in zip(img.cpu(), class_pred, prob):\n",
    "                samples.append((image, prediction, probability))\n",
    "\n",
    "    return model_pred, predictions_prob, true_labels, samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ClQNsitNGEhs",
    "outputId": "7390f05d-2455-4a3b-d387-66c2796d41a0"
   },
   "outputs": [],
   "source": [
    "# Set the random seed\n",
    "seed_everything(42)\n",
    "\n",
    "model = BaseModel().to(DEVICE)\n",
    "model.load_state_dict(torch.load('model.pt', map_location=DEVICE))\n",
    "\n",
    "# Run inference\n",
    "model_pred, predictions_prob, true_labels, samples = inference(model, test_loader, DEVICE)\n",
    "\n",
    "from sklearn.metrics import f1_score, precision_recall_curve, confusion_matrix\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(true_labels, predictions_prob)\n",
    "f1_scores = 2 * (precision * recall) / (precision + recall + 1e-10)\n",
    "\n",
    "print(\"f1 score: \", f1_scores)\n",
    "print(\"precision: \", precision)\n",
    "print(\"recall: \", recall)\n",
    "\n",
    "# Perform necessary visualizations and post-processing\n",
    "# Example: Plot PR Curve and Confusion Matrix\n",
    "plot_pr_curve(true_labels, predictions_prob)\n",
    "plot_confusion_matrix(true_labels, model_pred, [\"Declined\", \"Approved\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "CH_E0lbO7-AU",
    "outputId": "c90a72c7-26de-4128-babb-d56c47e88098"
   },
   "outputs": [],
   "source": [
    "def denormalize(image, mean, std):\n",
    "    # Perform denormalization for each channel\n",
    "    for c in range(3):  # RGB channels (C, H, W)\n",
    "        image[c] = image[c] * std[c] + mean[c]\n",
    "    return image\n",
    "\n",
    "# ImageNet statistics\n",
    "imagenet_mean = [0.485, 0.456, 0.406]\n",
    "imagenet_std = [0.229, 0.224, 0.225]\n",
    "\n",
    "for i, (image, prediction, probability) in enumerate(samples):\n",
    "    actual = true_labels[i]\n",
    "\n",
    "    if (prediction == 1 and actual == 0) or (prediction == 0 and actual == 1):\n",
    "        status = \"False Positive\" if prediction == 1 else \"False Negative\"\n",
    "\n",
    "        # Denormalize the image\n",
    "        image = denormalize(image.clone(), imagenet_mean, imagenet_std)  # Use .clone() to avoid modifying the original\n",
    "\n",
    "        # Transform dimensions and convert to numpy for visualization\n",
    "        image = image.permute(1, 2, 0).detach().cpu().numpy()  # (C, H, W) -> (H, W, C)\n",
    "        image = image.clip(0, 1)  # Clip values to the range 0–1\n",
    "\n",
    "        # Visualization\n",
    "        plt.imshow(image)\n",
    "        plt.title(f\"{status}: Prediction: {'Declined' if prediction == 0 else 'Approved'} ({probability:.2f})\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "ZpjunTLBm9qB",
    "ehZaPIKNjNpz"
   ],
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
