{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "from tqdm import tqdm  # Import tqdm for the progress bar\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import configuration settings\n",
    "# import config\n",
    "import config\n",
    "\n",
    "\n",
    "\n",
    "# Define a PyTorch Dataset\n",
    "class SmokeAlarmDataset(Dataset):\n",
    "    def __init__(self, df, image_dir, transform=None):\n",
    "        self.df = df\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "        self.label_map = {\"Approved\": 1, \"Declined\": 0}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        job_no = str(self.df.iloc[idx][\"job_no\"])\n",
    "        image_name = self.df.iloc[idx][\"image_name\"]\n",
    "        label = self.df.iloc[idx][\"image_status\"]\n",
    "        label = self.label_map.get(label, 0)\n",
    "\n",
    "        image_path = os.path.join(self.image_dir, job_no, image_name)\n",
    "\n",
    "        if not os.path.exists(image_path):\n",
    "            print(f\"Warning: Image not found at {image_path}. Skipping this file.\")\n",
    "            return None, None\n",
    "\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# Custom collate function to handle missing files\n",
    "def collate_fn(batch):\n",
    "    batch = [item for item in batch if item[0] is not None]\n",
    "    return torch.utils.data.dataloader.default_collate(batch)\n",
    "\n",
    "# Define transformations for data preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=config.NORMALIZE_MEAN, std=config.NORMALIZE_STD)\n",
    "])\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(config.CSV_FILE_PATH)\n",
    "\n",
    "# Split data into train, validation, and test sets\n",
    "train_df, temp_df = train_test_split(df, test_size=0.3, random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "\n",
    "# Initialize the datasets and dataloaders\n",
    "train_dataset = SmokeAlarmDataset(train_df, config.IMAGE_DIR, transform=transform)\n",
    "val_dataset = SmokeAlarmDataset(val_df, config.IMAGE_DIR, transform=transform)\n",
    "test_dataset = SmokeAlarmDataset(test_df, config.IMAGE_DIR, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=config.BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=config.BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=config.BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "# Define the model\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.model = getattr(models, config.MODEL_NAME)(pretrained=True)\n",
    "        self.model.fc = nn.Linear(self.model.fc.in_features, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.sigmoid(self.model(x))\n",
    "\n",
    "model = SimpleCNN()\n",
    "\n",
    "# Define loss and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=config.LEARNING_RATE)\n",
    "\n",
    "# Training loop with validation\n",
    "for epoch in range(config.NUM_EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    # Training phase\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{config.NUM_EPOCHS}\", leave=False)\n",
    "    for images, labels in progress_bar:\n",
    "        labels = labels.unsqueeze(1).float()  # Reshape labels for binary output\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Update progress bar description with current loss\n",
    "        progress_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{config.NUM_EPOCHS}], Training Loss: {running_loss / len(train_loader)}\")\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            labels = labels.unsqueeze(1).float()\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            preds = (outputs > 0.5).float()\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Calculate F1 Score\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{config.NUM_EPOCHS}], Validation Loss: {val_loss / len(val_loader)}, F1 Score: {f1}\")\n",
    "\n",
    "print(\"Training complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
