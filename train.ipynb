{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "from tqdm import tqdm  # Import tqdm for the progress bar\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "# Import configuration settings\n",
    "# import config\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "# 이미지 경로 설정\n",
    "base_dir = 'data/cropdata'\n",
    "\n",
    "# 결과를 저장할 리스트 초기화\n",
    "data = []\n",
    "\n",
    "df = pd.read_csv('data/images_data_filtered.csv')\n",
    "\n",
    "approved_df = df[df['image_status'] == 'Approved']\n",
    "declined_df = df[df['image_status'] == 'Declined']\n",
    "\n",
    "approved_sample = approved_df.sample(n=2000, random_state=42)\n",
    "df_undersampled = pd.concat([approved_sample, declined_df])\n",
    "\n",
    "# 데이터 셔플링 (랜덤 정렬)\n",
    "df_undersampled = df_undersampled.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# 결과를 CSV 파일로 저장\n",
    "df_undersampled.to_csv('data/undersampled_images_data.csv', index=False)\n",
    "print(\"Under-sampled CSV file created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/undersampled_images_data.csv')\n",
    "\n",
    "# Display all columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Display all rows\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# Display the first few rows of the data\n",
    "data.head()\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "data['image_status'].value_counts().plot(kind='bar', color=['skyblue', 'salmon'])\n",
    "plt.title('Distribution of Approved and Declined Images')\n",
    "plt.xlabel('Image Status')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the balanced CSV file\n",
    "df = pd.read_csv(config.CSV_FILE_PATH)\n",
    "\n",
    "# Define a PyTorch Dataset\n",
    "class SmokeAlarmDataset(Dataset):\n",
    "    def __init__(self, df, image_dir, transform=None):\n",
    "        self.df = df\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "        self.label_map = {\"Approved\": 1, \"Declined\": 0}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        job_no = str(self.df.iloc[idx][\"job_no\"])\n",
    "        image_name = self.df.iloc[idx][\"image_name\"]\n",
    "        label = self.df.iloc[idx][\"image_status\"]\n",
    "        label = self.label_map.get(label, 0)\n",
    "\n",
    "        image_path = os.path.join(self.image_dir, job_no, image_name)\n",
    "\n",
    "        if not os.path.exists(image_path):\n",
    "            print(f\"Warning: Image not found at {image_path}. Skipping this file.\")\n",
    "            return None, None\n",
    "\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# Custom collate function to handle missing files\n",
    "def collate_fn(batch):\n",
    "    batch = [item for item in batch if item[0] is not None]\n",
    "    return torch.utils.data.dataloader.default_collate(batch)\n",
    "\n",
    "# Define transformations for data preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((229, 229)), # InceptionV3 requires 299x299 input size\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=config.NORMALIZE_MEAN, std=config.NORMALIZE_STD)\n",
    "])\n",
    "\n",
    "\n",
    "# Split data into train, validation, and test sets\n",
    "train_df, temp_df = train_test_split(df, test_size=0.3, random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "\n",
    "# Initialize the datasets and dataloaders\n",
    "train_dataset = SmokeAlarmDataset(train_df, config.IMAGE_DIR, transform=transform)\n",
    "val_dataset = SmokeAlarmDataset(val_df, config.IMAGE_DIR, transform=transform)\n",
    "test_dataset = SmokeAlarmDataset(test_df, config.IMAGE_DIR, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=config.BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=config.BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=config.BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "#Define the Inception model\n",
    "class InceptionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(InceptionModel, self).__init__()\n",
    "        self.model = models.inception_v3(pretrained=True, aux_logits=True)  # Inception v3 with auxiliary logits\n",
    "        self.model.fc = nn.Sequential(\n",
    "            nn.Linear(self.model.fc.in_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, 1)  # Binary output\n",
    "        )\n",
    "        # Optional: Adjust the auxiliary classifier if needed\n",
    "        self.model.AuxLogits.fc = nn.Linear(self.model.AuxLogits.fc.in_features, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.model.training:\n",
    "            x, aux = self.model(x)\n",
    "            return x, aux  # Return main and auxiliary outputs for training\n",
    "        else:\n",
    "            x = self.model(x)\n",
    "            return x\n",
    "\n",
    "model = InceptionModel().to(config.DEVICE)\n",
    "\n",
    "# Define loss and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=config.LEARNING_RATE)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "f1_scores = []\n",
    "\n",
    "for epoch in range(config.NUM_EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    # Training phase\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{config.NUM_EPOCHS}\", leave=False)\n",
    "    for images, labels in progress_bar:\n",
    "        labels = labels.unsqueeze(1).float().to(config.DEVICE)\n",
    "        images = images.to(config.DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs, aux_outputs = model(images)  # Expect main and auxiliary outputs\n",
    "        loss1 = criterion(outputs, labels)\n",
    "        loss2 = criterion(aux_outputs, labels)\n",
    "        loss = loss1 + 0.4 * loss2  # Main loss + weighted auxiliary loss\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        progress_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_losses.append(train_loss)\n",
    "    print(f\"Epoch [{epoch + 1}/{config.NUM_EPOCHS}], Training Loss: {train_loss}\")\n",
    "\n",
    "    # Validation phase (no auxiliary output needed)\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            labels = labels.unsqueeze(1).float().to(config.DEVICE)\n",
    "            images = images.to(config.DEVICE)\n",
    "\n",
    "            outputs = model(images)  # Only get main output for validation\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            preds = (torch.sigmoid(outputs) > 0.5).float()\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    val_loss = val_loss / len(val_loader)\n",
    "    val_losses.append(val_loss)\n",
    "\n",
    "    # Calculate F1 Score\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "    f1_scores.append(f1)\n",
    "    print(f\"Epoch [{epoch + 1}/{config.NUM_EPOCHS}], Validation Loss: {val_loss}, F1 Score: {f1}\")\n",
    "\n",
    "# Plot Training and Validation Loss\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss over Epochs')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot F1 Score\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(f1_scores, label='F1 Score')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.title('F1 Score over Epochs')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model_weights.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 인스턴스 생성\n",
    "model = SimpleCNN()  # 미리 정의된 모델 클래스\n",
    "\n",
    "# 상태 dict 불러오기 및 모델에 로드\n",
    "model.load_state_dict(torch.load('model_weights.pt'))\n",
    "model.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "# 추론용 데이터 로더 정의\n",
    "infer_loader = DataLoader(train_dataset, batch_size=config.BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "\n",
    "with torch.no_grad():  # 추론 시에는 gradient 계산 불필요\n",
    "    for images, labels in infer_loader:\n",
    "        outputs = model(images)\n",
    "        preds = (outputs > 0.5).float()  # 이진 분류일 경우 임계값 설정\n",
    "        \n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# 예측 결과를 numpy 배열로 변환\n",
    "import numpy as np\n",
    "all_preds = np.array(all_preds)\n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "# 필요한 경우 정확도 계산\n",
    "accuracy = (all_preds == all_labels).mean()\n",
    "print(f\"Overall accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = f1_score(all_labels, all_preds)\n",
    "print(f\"F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
